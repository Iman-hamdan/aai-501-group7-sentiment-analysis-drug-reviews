{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of drug reviews using Logistic Regression\n",
    "This notebook builds an LSTM model to classify drug reviews as either positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Contributors\n",
    "\n",
    "-   Michael Skirvin : EDA , Feature Engeneering, Model Training and Evaluation, Conclusions.\n",
    "\n",
    "-   Swathi Subramanyam & Iman Hamdan : Code Review "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mikes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "\n",
    "•\tLoads Data: Reads the training (drugsComTrain_raw.tsv) and testing (drugsComTest_raw.tsv) datasets from the data folder.\n",
    "\n",
    "•\tProcesses Data:\n",
    "\n",
    "Converts the drugName and condition columns to uppercase for consistency.\n",
    "\n",
    "Calculates the number of unique drugs and conditions and prints these counts.\n",
    "\n",
    "•\tFeature Engineering:\n",
    "\n",
    "Adds a new column, review_len, to store the length of each review.\n",
    "\n",
    "Adds a binary target column, is_positive:\n",
    "\n",
    "1: If the rating > 7 (positive review).\n",
    "\n",
    "0: Otherwise (negative review).\n",
    "\n",
    "•\tBalances Classes:\n",
    "\n",
    "Calls the balance_class function to handle class imbalance in both the training and testing datasets by resampling.\n",
    "\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is used to calculate sentiment polarity scores for each review.\n",
    "\n",
    "•\tCalculates the following sentiment scores for each review:\n",
    "\n",
    "Negative (neg): Proportion of negative sentiment in the review.\n",
    "\n",
    "Positive (pos): Proportion of positive sentiment.\n",
    "\n",
    "Compound: Overall sentiment score (-1 to 1) summarizing the polarity.\n",
    "\n",
    "Appends these scores as new columns (neg, pos, compound) to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test():\n",
    "    cwd = os.getcwd()\n",
    "    # print(cwd)\n",
    "\n",
    "    df_train = pd.read_csv(cwd + \"\\data\\drugsComTrain_raw.tsv\", sep='\\t')\n",
    "    df_test = pd.read_csv(cwd + \"\\data\\drugsComTest_raw.tsv\", sep='\\t')\n",
    "\n",
    "    df_list = [df_train, df_test]\n",
    "\n",
    "    # print(f\"train_len={train_len} test_len={test_len} df_len={len(df)}\")\n",
    "    print(df_train.columns)\n",
    "\n",
    "    df_train['drugName'] = df_train['drugName'].str.upper()\n",
    "    number_of_drugs = len(df_train['drugName'].unique())\n",
    "    print(f\"Number of drugs = {number_of_drugs}\")\n",
    "\n",
    "    df_train['condition'] = df_train['condition'].str.upper()\n",
    "    number_of_drugs = len(df_train['condition'].unique())\n",
    "    print(f\"Number of condition = {number_of_drugs}\")\n",
    "\n",
    "    # Generate columns for review length and positive reviews.  If the rating is greater than 7 of 10, assume it is positive\n",
    "    for df in df_list:\n",
    "        df['review_len'] = df['review'].str.len()\n",
    "        df['is_positive'] = np.where(df['rating'] > 7, 1, 0)\n",
    "\n",
    "    df_train = balance_class(df_train, 'is_positive')\n",
    "    df_test = balance_class(df_test, 'is_positive')\n",
    "    return df_train, df_test\n",
    "\n",
    "def balance_class(df, colname):\n",
    "    class1 = df[df[colname] == 1].copy()\n",
    "    class2 = df[df[colname] == 0].copy()\n",
    "\n",
    "    if len(class1) > len(class2):\n",
    "        maj_class = class1\n",
    "        min_class = class2\n",
    "    else:\n",
    "        maj_class = class2\n",
    "        min_class = class1 \n",
    "\n",
    "    maj_downsample = resample(maj_class, replace=False, n_samples=len(min_class), random_state=0)\n",
    "\n",
    "    df_balanced = pd.concat([min_class, maj_downsample])\n",
    "    return df_balanced\n",
    "\n",
    "# https://www.nltk.org/howto/sentiment.html\n",
    "def add_vader(df):\n",
    "    neg_list, pos_list, compound_list = [], [], []\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    #for index, value in df['review'].items():\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ss = sid.polarity_scores(row['review'])\n",
    "        neg_list.append(ss['neg'])\n",
    "        pos_list.append(ss['pos'])\n",
    "        compound_list.append(ss['compound'])\n",
    "\n",
    "    df['neg'] = neg_list\n",
    "    df['pos'] = pos_list\n",
    "    df['compound'] = compound_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tFeature Preparation:\n",
    "\n",
    "•\tCombines textual analysis (review_len) with sentiment polarity scores (neg, pos, compound) for a richer feature set.\n",
    "\n",
    "2.\tBinary Sentiment Labels:\n",
    "\n",
    "•\ty_train and y_test are used to train and evaluate the model on a binary sentiment classification task.\n",
    "\n",
    "3.\tSentiment Analysis Integration:\n",
    "\n",
    "•\tIncorporates VADER sentiment scores as meaningful features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(127774, 1), y_train.shape=(127774,)\n",
      "X_test.shape=(42834, 1), y_test.shape=(42834,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8101a90cefab4f5690623e184d3daa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5f256e82194af793328257addf2c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train, df_test = get_train_test()\n",
    "\n",
    "# Create dataframe with the length of the review as the only feature\n",
    "X_train = df_train[['review_len']].copy()\n",
    "y_train = df_train['is_positive'].copy()\n",
    "X_test = df_test[['review_len']].copy()\n",
    "y_test = df_test['is_positive'].copy()\n",
    "\n",
    "# Get shapes of dataframes\n",
    "print(f\"X_train.shape={X_train.shape}, y_train.shape={y_train.shape}\")\n",
    "print(f\"X_test.shape={X_test.shape}, y_test.shape={y_test.shape}\")\n",
    "\n",
    "# Get VADER columns for negative, positive, and compund values\n",
    "X_train_vader = add_vader(df_train)\n",
    "X_test_vader = add_vader(df_test)\n",
    "\n",
    "# Add columns to dataset\n",
    "for colname in ['neg', 'pos', 'compound']:\n",
    "    X_train[colname] = X_train_vader[colname]\n",
    "    X_test[colname] = X_test_vader[colname]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scaling: Standardizes the feature values to improve the stability and performance of logistic regression.\n",
    "\n",
    "Model Training: Trains a logistic regression model on the scaled training data.\n",
    "\n",
    "Model Evaluation: Measures the accuracy of predictions on the test set, providing insight into the model’s generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(127774, 4), y_train.shape=(127774,)\n",
      "X_test.shape=(42834, 4), y_test.shape=(42834,)\n",
      "Accuracy=0.6287\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train.shape={X_train.shape}, y_train.shape={y_train.shape}\")\n",
    "print(f\"X_test.shape={X_test.shape}, y_test.shape={y_test.shape}\")\n",
    "\n",
    "scaler_train = preprocessing.StandardScaler().fit(X_train)\n",
    "# Create and fit scaler object for test data\n",
    "scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
    "# Scaled version of x_train\n",
    "x_train_scale = scaler_train.transform(X_train)\n",
    "# Scaled version of x_train\n",
    "x_test_scale = scaler_test.transform(X_test)\n",
    "\n",
    "# Build logistic model and fit\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_scale, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test_scale)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy={accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferences:\n",
    "\n",
    "\n",
    "Logistic regression is a linear model and may not fully capture the complexity of non-linear relationships in the data.\n",
    "\n",
    "Sentiment analysis often involves contextual and nuanced language, which might not be effectively modeled by a simple linear classifier.\n",
    "\n",
    "The features (review_len, neg, pos, compound) are limited in scope and may not fully represent the richness of the review text.\n",
    "\n",
    "#### Recommendations and further improvements:\n",
    "\n",
    "Move beyond basic features like review_len and VADER scores.\n",
    "\n",
    "Use advanced NLP techniques to capture richer textual information:\n",
    "  \n",
    "   TF-IDF: Vectorize the review text using Term Frequency-Inverse Document Frequency to highlight important words.\n",
    "\n",
    "   Word Embeddings: Use pre-trained embeddings (e.g., GloVe, Word2Vec) to represent words in a dense, semantic space.\n",
    "\n",
    "   Contextualized Embeddings: Use models like BERT or RoBERTa to extract sentence-level embeddings, capturing the context of words.\n",
    "\n",
    "Experiment with Neural Networks,\n",
    "\n",
    "Feedforward Neural Networks (FNN): Use the extracted features (review_len, sentiment scores) as input to an FNN for classification.\n",
    "\n",
    "Recurrent Neural Networks (RNN) or LSTMs: Use these to handle sequential data and capture dependencies in the review text.\n",
    "\n",
    "Transformers: Fine-tune pre-trained models like BERT or DistilBERT for sentiment analysis.\n",
    "\n",
    "Evaluate the new models using standard metrics like accuracy, precision, recall, and F1-score.\n",
    "\n",
    "Compare the performance of neural networks and pre-trained models against logistic regression to demonstrate improvements.\n",
    "\n",
    "Transitioning to neural networks or advanced NLP methods will likely result in significant improvements in performance and the ability to generalize better to unseen data. Starting with simpler neural architectures like FNNs or LSTMs and gradually moving to transformers like BERT would provide a structured way to build.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A500",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
